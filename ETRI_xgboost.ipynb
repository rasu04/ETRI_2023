{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2352,
     "status": "ok",
     "timestamp": 1681260006564,
     "user": {
      "displayName": "김진솔",
      "userId": "11702173973778170953"
     },
     "user_tz": -540
    },
    "id": "gRTQWoCOlkD0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_absolute_error, precision_score, recall_score, f1_score\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier, cv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('{파일경로}/lifelog_data_2018.csv')\n",
    "df2 = pd.read_csv('{파일경로}/lifelog_data_2019.csv')\n",
    "df3 = pd.read_csv('{파일경로}/lifelog_data_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681260025572,
     "user": {
      "displayName": "김진솔",
      "userId": "11702173973778170953"
     },
     "user_tz": -540
    },
    "id": "lsknUQEP2aXs"
   },
   "outputs": [],
   "source": [
    "def engineering(n, d):\n",
    "    # 성별 인코딩\n",
    "    d['gender'] = d['gender'].apply(lambda x:0 if x == 'M' else 1)\n",
    "    # 날짜 변환\n",
    "    d['date'] = pd.to_datetime(d['date'])\n",
    "\n",
    "    # 스트레스(target)\n",
    "    d['pmStress'] = d['pmStress'] - 1\n",
    "    # XGBoost의 경우는 0부터 시작 > 나중에 좀 더 찾아보기\n",
    "    # Stacking을 위해 모든 모델 pmStress 범위 변경\n",
    "    \n",
    "    # 감정변화비율 = 오후감정/오전감정\n",
    "    d['emotionChangeRate'] = d['pmEmotion'] / d['amEmotion']\n",
    "    # 긍정변화평균 = emotion1~7의 평균\n",
    "    d['positiveMean'] = d.filter(regex='Positive').mean(axis=1)\n",
    "    # 긴장변화평균 = emotion1~7의 평균\n",
    "    d['tensionnMean'] = d.filter(regex='Tension').mean(axis=1)\n",
    "    \n",
    "    # 긍정비율 = Positive5~7 / 1~3 > 4는 중앙값으로 진행하지 않음\n",
    "    d['positiveRate'] = d[['emotionPositive5', 'emotionPositive6', 'emotionPositive7']].sum(axis=1) / d[['emotionPositive1', 'emotionPositive2', 'emotionPositive3']].sum(axis=1)\n",
    "    # 긴장비율 = Tension5~7 / 1~3 > 4는 중앙값으로 진행하지 않음\n",
    "    d['tensionRate'] = d[['emotionTension5', 'emotionTension6', 'emotionTension7']].sum(axis=1) / d[['emotionTension1', 'emotionTension2', 'emotionTension3']].sum(axis=1)\n",
    "    \n",
    "    # 긍정감정의 임시 테이블\n",
    "    pos_temp = d.filter(regex='Positive')\n",
    "    # 가장 높은 긍정감정의 숫자(1~7)\n",
    "    d['topPositive'] = pos_temp.idxmax(axis=1).apply(lambda x:int(x[-1]))\n",
    "    # 가장 낮은 긍정감정의 숫자(1~7)\n",
    "    d['botPositive'] = pos_temp.idxmin(axis=1).apply(lambda x:int(x[-1]))\n",
    "    \n",
    "    # 긍정 수치 1~7 * count 수\n",
    "    for p, c in enumerate(pos_temp.columns):\n",
    "        d.loc[:, [c]] = d.loc[:, [c]] * (p+1)\n",
    "        \n",
    "    del pos_temp\n",
    "    \n",
    "    # 긴장감정의 임시 테이블\n",
    "    ten_temp = d.filter(regex='Tension')\n",
    "    # 가장 높은 긴장감정의 숫자(1~7)\n",
    "    d['topTension'] = ten_temp.idxmax(axis=1).apply(lambda x:int(x[-1]))\n",
    "    # 가장 낮은 긴장감정의 숫자(1~7)\n",
    "    d['botTension'] = ten_temp.idxmin(axis=1).apply(lambda x:int(x[-1]))\n",
    "    \n",
    "    # 긴장 수치 1~7 * count 수\n",
    "    for t, c in enumerate(ten_temp.columns):\n",
    "        d.loc[:, [c]] = d.loc[:, [c]] * (t+1)\n",
    "    \n",
    "    del ten_temp\n",
    "    \n",
    "    # 수치 반영 긍정 평균\n",
    "    d['positiveWMean'] = d.filter(regex='Positive').mean(axis=1)\n",
    "    # 수치 반영 긴장 평균\n",
    "    d['tensionWMean'] = d.filter(regex='Tension').mean(axis=1)\n",
    "    \n",
    "    # 수치 반영 긍정 비율\n",
    "    d['positiveWRate'] = d[['emotionPositive5', 'emotionPositive6', 'emotionPositive7']].sum(axis=1) / d[['emotionPositive1', 'emotionPositive2', 'emotionPositive3']].sum(axis=1)\n",
    "    # 수치 반영 긴장 비율\n",
    "    d['tensionWRate'] = d[['emotionTension5', 'emotionTension6', 'emotionTension7']].sum(axis=1) / d[['emotionTension1', 'emotionTension2', 'emotionTension3']].sum(axis=1)\n",
    "    \n",
    "    # 최고 수치를 반영한 오전 감정 = (오전 감정 * (최고 감정 + 최고 긴장)) / 14\n",
    "    d['aCtPT'] = round(d['amEmotion'] * (d['topPositive'] + d['topTension']) / 14)\n",
    "    # 최고 수치를 반영한 오전 컨디션 = (오전 감정 * (최고 감정 + 최고 긴장)) / 14\n",
    "    d['aEtPT'] = round(d['amCondition'] * (d['topPositive'] + d['topTension']) / 14)\n",
    "    # 최고 수치를 반영한 오후 감정 = (오전 감정 * (최고 감정 + 최고 긴장)) / 14\n",
    "    d['pEtPT'] = round(d['pmEmotion'] * (d['topPositive'] + d['topTension']) / 14)\n",
    "    \n",
    "    d['aCEpEtPTm'] = (d['aCtPT'] + d['aEtPT'] + d['pEtPT'])\n",
    "    \n",
    "    # 긍정적인지 = 수치 반영 긍정 평균이 중앙값보다 크면 1 아니면 0\n",
    "    d['positive'] = d['positiveWRate'].apply(lambda x:1 if x > d['positiveWRate'].median() else 0)\n",
    "    # 부정적인지 = 수치 반영 긍정 평균이 중앙값보다 작으면 1 아니면 0\n",
    "    d['negative'] = d['positiveWRate'].apply(lambda x:1 if x < d['positiveWRate'].median() else 0)\n",
    "    \n",
    "    # 긴장 상태인지 = 수치 반영 긴장 평균이 중앙값보다 크면 1 아니면 0\n",
    "    d['aroused'] = d['tensionWRate'].apply(lambda x:1 if x > d['tensionWRate'].median() else 0)\n",
    "    # 편안한 상태인지 = 수치 반영 긴장 평균이 중앙값보다 작으면 1 아니면 0\n",
    "    d['relaxed'] = d['tensionWRate'].apply(lambda x:1 if x < d['tensionWRate'].median() else 0)\n",
    "    \n",
    "    # 활동 비율 = 자전거, 도보의 합 / 운송수단, 가만히 있기의 합\n",
    "    d['activityRate'] = d[['on_bicycle', 'on_foot']].sum(axis=1) / d[['in_vehicle', 'still']].sum(axis=1)\n",
    "    # 0으로 나누기된 것을 0으로 치환 > inf 값을 가짐\n",
    "    d.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    d.dropna(inplace=True)\n",
    "    d.sample(n=d.shape[0], random_state=47)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, d in enumerate([df1, df2, df3]):\n",
    "    globals() [f'df{n+1}'] = engineering(n, d.copy())\n",
    "df = pd.concat([df1, df2, df3], axis=0)\n",
    "df = df[[c for c in df.columns if c not in ['pmStress']] + ['pmStress']]\n",
    "df.drop(['date', 'userId'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 32699,
     "status": "ok",
     "timestamp": 1681261035302,
     "user": {
      "displayName": "김진솔",
      "userId": "11702173973778170953"
     },
     "user_tz": -540
    },
    "id": "EBm0rfaE-2k-",
    "outputId": "d738284d-d2a0-47c9-9eb6-331a2f42709e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.6086956521739131\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.4956521739130435\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5652173913043478\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5217391304347826\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5391304347826087\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5391304347826087\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5304347826086957\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5217391304347826\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5565217391304348\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.4782608695652174\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5478260869565217\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5043478260869565\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5043478260869565\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.4782608695652174\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5739130434782609\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5304347826086957\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5304347826086957\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5391304347826087\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5391304347826087\n",
      "============================================================\n",
      "(815, 78) (236, 78) (115, 78)\n",
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.5739130434782609\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "test_accuracy_list = []\n",
    "\n",
    "for i in range(20):\n",
    "    train = pd.DataFrame()\n",
    "    valid = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "\n",
    "    for i in range(5):\n",
    "        train = pd.concat([train, df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][:round(len(df) / 5 * 0.7)]], axis=0)\n",
    "        valid = pd.concat([valid, df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][round(len(df) / 5 * 0.7):-round(len(df) / 5 * 0.1)]], axis=0)\n",
    "        test = pd.concat([test, df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][-round(len(df) / 5 * 0.1):]], axis=0)\n",
    "\n",
    "        # 동 수로 뽑을 때\n",
    "    #     temp = df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][:151]\n",
    "    #     train = pd.concat([train, temp[:round(151 * 0.7)]], axis=0)\n",
    "    #     valid = pd.concat([valid, temp[round(151 * 0.7):-round(151 * 0.1)]], axis=0)\n",
    "    #     test = pd.concat([test, temp[-round(151 * 0.1):]], axis=0)\n",
    "\n",
    "    train = train.sample(n=train.shape[0]) # , random_state=1234)\n",
    "    valid = valid.sample(n=valid.shape[0]) # , random_state=1234)\n",
    "    test = test.sample(n=test.shape[0], random_state = 1234)\n",
    "    print(train.shape, valid.shape, test.shape)\n",
    "\n",
    "    df = pd.concat([train, test, valid], axis=0)\n",
    "    # sns.countplot(x='pmStress', data=df)\n",
    "\n",
    "    train_X = train.iloc[:, 2:-1].values\n",
    "    train_y = train.iloc[:, -1].values.reshape(-1, 1)\n",
    "    valid_X = valid.iloc[:, 2:-1].values\n",
    "    valid_y = valid.iloc[:, -1].values.reshape(-1, 1)\n",
    "    test_X = test.iloc[:, 2:-1].values\n",
    "    test_y = test.iloc[:, -1].values.reshape(-1, 1)\n",
    "\n",
    "    lr = 0.1\n",
    "    md = 4\n",
    "    ne = 5\n",
    "    ss = 0.9\n",
    "    mc = 0\n",
    "    g = 0.5\n",
    "    pt = 10\n",
    "    b = 'gbtree'\n",
    "    tm = 'hist'\n",
    "    em = 'mlogloss'\n",
    "    o = 'multi:softmax'\n",
    "    l = 0.7\n",
    "    a = 0.7\n",
    "    cb = 0.2\n",
    "    params = {'learning_rate' : lr, 'max_depth': md, 'n_estimators': ne,\n",
    "            'num_class' : 5, 'subsample': ss,\n",
    "            'colsample_bytree': cb, 'min_child_weight': mc,\n",
    "            'lambda': l, 'alpha': a,\n",
    "            'gamma': g, 'num_parallel_tree' : pt,\n",
    "            'booster': b, 'tree_method': tm,\n",
    "            'eval_metric' : em, 'objective': o,\n",
    "            'random_state' : 6666, 'verbosity': 0}\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    model.fit(train_X.copy(), train_y.copy())\n",
    "\n",
    "    pred_XGB = model.predict(test_X.copy())\n",
    "    accuracy = accuracy_score(test_y.copy(), pred_XGB.copy())\n",
    "    print(lr, md, ne, ss, mc, g, pt, b, tm, em, o, l, a, cb, '\\naccuracy :', accuracy)\n",
    "    test_accuracy_list.append(accuracy)\n",
    "    print('=='*30)\n",
    "# resul_XGB = pd.DataFrame({'Test Accuracy': test_accuracy_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_XGB = pd.DataFrame(pred_XGB)\n",
    "pred_XGB.columns  = ['XGB']\n",
    "pred_XGB.to_csv('XGB.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
