{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gRTQWoCOlkD0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_absolute_error, precision_score, recall_score, f1_score\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier, cv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineering(n, d):\n",
    "    # 성별 인코딩\n",
    "    d['gender'] = d['gender'].apply(lambda x:0 if x == 'M' else 1)\n",
    "    # 날짜 변환\n",
    "    d['date'] = pd.to_datetime(d['date'])\n",
    "    # 스트레스(target)\n",
    "    d['pmStress'] = d['pmStress'] - 1\n",
    "    \n",
    "    # 감정변화비율 = 오후감정/오전감정\n",
    "    d['emotionChangeRate'] = d['pmEmotion'] / d['amEmotion']\n",
    "    # 긍정변화평균 = emotion1~7의 평균\n",
    "    d['positiveMean'] = d.filter(regex='Positive').mean(axis=1)\n",
    "    # 긴장변화평균 = emotion1~7의 평균\n",
    "    d['tensionnMean'] = d.filter(regex='Tension').mean(axis=1)\n",
    "    \n",
    "    # 긍정비율 = Positive5~7 / 1~3 > 4는 중앙값으로 진행하지 않음\n",
    "    d['positiveRate'] = d[['emotionPositive5', 'emotionPositive6', 'emotionPositive7']].sum(axis=1) / d[['emotionPositive1', 'emotionPositive2', 'emotionPositive3']].sum(axis=1)\n",
    "    # 긴장비율 = Tension5~7 / 1~3 > 4는 중앙값으로 진행하지 않음\n",
    "    d['tensionRate'] = d[['emotionTension5', 'emotionTension6', 'emotionTension7']].sum(axis=1) / d[['emotionTension1', 'emotionTension2', 'emotionTension3']].sum(axis=1)\n",
    "    \n",
    "    # 긍정감정의 임시 테이블\n",
    "    pos_temp = d.filter(regex='Positive')\n",
    "    # 가장 높은 긍정감정의 숫자(1~7)\n",
    "    d['topPositive'] = pos_temp.idxmax(axis=1).apply(lambda x:int(x[-1]))\n",
    "    # 가장 낮은 긍정감정의 숫자(1~7)\n",
    "    d['botPositive'] = pos_temp.idxmin(axis=1).apply(lambda x:int(x[-1]))\n",
    "    \n",
    "    # 긍정 수치 1~7 * count 수\n",
    "    for p, c in enumerate(pos_temp.columns):\n",
    "        d.loc[:, [c]] = d.loc[:, [c]] * (p+1)\n",
    "        \n",
    "    del pos_temp\n",
    "    \n",
    "    # 긴장감정의 임시 테이블\n",
    "    ten_temp = d.filter(regex='Tension')\n",
    "    # 가장 높은 긴장감정의 숫자(1~7)\n",
    "    d['topTension'] = ten_temp.idxmax(axis=1).apply(lambda x:int(x[-1]))\n",
    "    # 가장 낮은 긴장감정의 숫자(1~7)\n",
    "    d['botTension'] = ten_temp.idxmin(axis=1).apply(lambda x:int(x[-1]))\n",
    "    \n",
    "    # 긴장 수치 1~7 * count 수\n",
    "    for t, c in enumerate(ten_temp.columns):\n",
    "        d.loc[:, [c]] = d.loc[:, [c]] * (t+1)\n",
    "    \n",
    "    del ten_temp\n",
    "    \n",
    "    # 수치 반영 긍정 평균\n",
    "    d['positiveWMean'] = d.filter(regex='Positive').mean(axis=1)\n",
    "    # 수치 반영 긴장 평균\n",
    "    d['tensionWMean'] = d.filter(regex='Tension').mean(axis=1)\n",
    "    \n",
    "    # 수치 반영 긍정 비율\n",
    "    d['positiveWRate'] = d[['emotionPositive5', 'emotionPositive6', 'emotionPositive7']].sum(axis=1) / d[['emotionPositive1', 'emotionPositive2', 'emotionPositive3']].sum(axis=1)\n",
    "    # 수치 반영 긴장 비율\n",
    "    d['tensionWRate'] = d[['emotionTension5', 'emotionTension6', 'emotionTension7']].sum(axis=1) / d[['emotionTension1', 'emotionTension2', 'emotionTension3']].sum(axis=1)\n",
    "    \n",
    "    # 오전 컨디션에 긍정/긴장 반영 = 오전 컨디션 * (수치 반영 긍정 평균 + 수치 반영 긴장 평균) / 7 -> 수치가 1~7이니까 그냥 7로 나누어 봄ㅎㅎ..\n",
    "    d['aCmET'] = round(d['amCondition'] * (d['positiveWMean'] + d['tensionWMean']) / 7)\n",
    "    # 오전 감정에 긍정/긴장 반영 = 오전 감정 * (수치 반영 긍정 평균 + 수치 반영 긴장 평균) / 7 -> 이것도\n",
    "    d['aEmET'] = round(d['amEmotion'] * (d['positiveWMean'] + d['tensionWMean']) / 7)\n",
    "    # 오전 컨디션/감정에 긍정 긴장 반영한 것의 평균을 냄\n",
    "    d['aCEmET'] = round((d['aCmET'] + d['aEmET']) / 2)\n",
    "    \n",
    "    # 오전 컨디션 긍정/긴장 반영에 오후 감정을 더한 뒤 평균을 냄\n",
    "    d['aCmETpE'] = round((d['aCmET'] + d['pmEmotion']) / 2)\n",
    "    # 오전 감정 긍정/긴장 반영에 오후 감정을 더한 뒤 평균을 냄\n",
    "    d['aEmETpE'] = round((d['aEmET'] + d['pmEmotion']) / 2)\n",
    "    # 오전 컨디션/감정 긍정/긴장 반영에 오후 감정을 더한 뒤 평균을 냄\n",
    "    d['aCEmETpE'] = round((d['aCEmET'] + d['pmEmotion']) / 2)\n",
    "    \n",
    "    # 최고 수치를 반영한 오전 감정 = (오전 감정 * (최고 감정 + 최고 긴장)) / 14\n",
    "    d['aCtPT'] = round(d['amEmotion'] * (d['topPositive'] + d['topTension']) / 14)\n",
    "    # 최고 수치를 반영한 오전 컨디션 = (오전 감정 * (최고 감정 + 최고 긴장)) / 14\n",
    "    d['aEtPT'] = round(d['amCondition'] * (d['topPositive'] + d['topTension']) / 14)\n",
    "    # 최고 수치를 반영한 오후 감정 = (오전 감정 * (최고 감정 + 최고 긴장)) / 14\n",
    "    d['pEtPT'] = round(d['pmEmotion'] * (d['topPositive'] + d['topTension']) / 14)\n",
    "    \n",
    "    # 둘 중에 하나로 쓰거나 컬럼명 변경해서 모두 써도 됩니다.\n",
    "    # (최고 수치를 반영한 오전 컨디션 + 최고 수치를 반영한 오전 감정 + 최고 수치를 반영한 오후 감정) / 3\n",
    "    # (최고 수치를 반영한 오전 컨디션 + 최고 수치를 반영한 오전 감정 + 최고 수치를 반영한 오후 감정)\n",
    "#     d['aCEpEtPTm'] = round((d['aCtPT'] + d['aEtPT'] + d['pEtPT']) / 3)\n",
    "    d['aCEpEtPTm'] = (d['aCtPT'] + d['aEtPT'] + d['pEtPT'])\n",
    "    \n",
    "    # 긍정적인지 = 수치 반영 긍정 평균이 중앙값보다 크면 1 아니면 0\n",
    "    d['positive'] = d['positiveWRate'].apply(lambda x:1 if x > d['positiveWRate'].median() else 0)\n",
    "    # 부정적인지 = 수치 반영 긍정 평균이 중앙값보다 작으면 1 아니면 0\n",
    "    d['negative'] = d['positiveWRate'].apply(lambda x:1 if x < d['positiveWRate'].median() else 0)\n",
    "    \n",
    "    # 긴장 상태인지 = 수치 반영 긴장 평균이 중앙값보다 크면 1 아니면 0\n",
    "    d['aroused'] = d['tensionWRate'].apply(lambda x:1 if x > d['tensionWRate'].median() else 0)\n",
    "    # 편안한 상태인지 = 수치 반영 긴장 평균이 중앙값보다 작으면 1 아니면 0\n",
    "    d['relaxed'] = d['tensionWRate'].apply(lambda x:1 if x < d['tensionWRate'].median() else 0)\n",
    "    \n",
    "    # 활동 비율 = 자전거, 도보의 합 / 운송수단, 가만히 있기의 합\n",
    "    d['activityRate'] = d[['on_bicycle', 'on_foot']].sum(axis=1) / d[['in_vehicle', 'still']].sum(axis=1)\n",
    "    # 0으로 나누기된 것을 0으로 치환\n",
    "    d.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    d.dropna(inplace=True)\n",
    "    # random_state는 잘 나오는 것으로 바꿔보세요! 제가 해본 것 : 1111, 2222, 3333, 4444, 5555, 6666, 7777, 8888, 9999, 1234\n",
    "    d.sample(n=d.shape[0], random_state=8888)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mti7tu3Flbuq"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'C:\\Users\\rian\\Documents\\2023\\02.nonmun\\02.result\\lifelog_data_2018.csv')\n",
    "df2 = pd.read_csv(r'C:\\Users\\rian\\Documents\\2023\\02.nonmun\\02.result\\lifelog_data_2019.csv')\n",
    "df3 = pd.read_csv(r'C:\\Users\\rian\\Documents\\2023\\02.nonmun\\02.result\\lifelog_data_2020.csv')\n",
    "for n, d in enumerate([df1, df2, df3]):\n",
    "    globals() [f'df{n+1}'] = engineering(n, d.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "4ySl_P6OpWMA"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[c for c in df.columns if c not in ['pmStress']] + ['pmStress']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rtC-hN4Tpcmu"
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "valid = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    train = pd.concat([train, df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][:round(len(df) / 5 * 0.7)]], axis=0)\n",
    "    valid = pd.concat([valid, df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][round(len(df) / 5 * 0.7):-round(len(df) / 5 * 0.1)]], axis=0)\n",
    "    test = pd.concat([test, df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][-round(len(df) / 5 * 0.1):]], axis=0)\n",
    "\n",
    "    # 동 수로 뽑을 때\n",
    "#     temp = df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][:151]\n",
    "#     train = pd.concat([train, temp[:round(151 * 0.7)]], axis=0)\n",
    "#     valid = pd.concat([valid, temp[round(151 * 0.7):-round(151 * 0.1)]], axis=0)\n",
    "#     test = pd.concat([test, temp[-round(151 * 0.1):]], axis=0)\n",
    "\n",
    "train = train.sample(n=train.shape[0]) # , random_state=1234)\n",
    "valid = valid.sample(n=valid.shape[0]) # , random_state=1234)\n",
    "test = test.sample(n=test.shape[0]) # , random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "5x2OEDX6E4lj",
    "outputId": "90cf1ee7-a8a6-474d-afdc-a14887d2feab"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train, test, valid], axis=0)\n",
    "# sns.countplot(x='pmStress', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "oWUwKpVylTov"
   },
   "outputs": [],
   "source": [
    "train_X = train.iloc[:, 2:-1].values\n",
    "train_y = train.iloc[:, -1].values.reshape(-1, 1)\n",
    "valid_X = valid.iloc[:, 2:-1].values\n",
    "valid_y = valid.iloc[:, -1].values.reshape(-1, 1)\n",
    "test_X = test.iloc[:, 2:-1].values\n",
    "test_y = test.iloc[:, -1].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMzxxRxNFcii",
    "outputId": "07cfa44b-dcc5-4f87-a8f7-f735e8129215",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 4 5 0.9 0 0.5 10 gbtree hist mlogloss multi:softmax 0.7 0.7 0.2 \n",
      "accuracy : 0.580952380952381\n"
     ]
    }
   ],
   "source": [
    "# learning rate\n",
    "lr = 0.1\n",
    "# max_depth\n",
    "md = 4\n",
    "# n_estimators\n",
    "ne = 5\n",
    "# subsample\n",
    "ss = 0.9\n",
    "# min_child_weight\n",
    "mc = 0\n",
    "# gamma\n",
    "g = 0.5\n",
    "# num_parallel_tree\n",
    "pt = 10\n",
    "# booster\n",
    "b = 'gbtree'\n",
    "# tree_method\n",
    "tm = 'hist'\n",
    "# eval_metric\n",
    "em = 'mlogloss'\n",
    "# objective\n",
    "o = 'multi:softmax'\n",
    "# lambda\n",
    "l = 0.7\n",
    "# alpha\n",
    "a = 0.7\n",
    "# coldample_bytree\n",
    "cb = 0.2\n",
    "\n",
    "params = {'learning_rate' : lr, 'max_depth': md, 'n_estimators': ne,\n",
    "        'num_class' : 5, 'subsample': ss,\n",
    "        'colsample_bytree': cb, 'min_child_weight': mc,\n",
    "        'lambda': l, 'alpha': a,\n",
    "        'gamma': g, 'num_parallel_tree' : pt,\n",
    "        'booster': b, 'tree_method': tm,\n",
    "        'eval_metric' : em, 'objective': o,\n",
    "        'random_state' : 6666, 'verbosity': 0}\n",
    "\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "model.fit(train_X.copy(), train_y.copy(),\n",
    "        eval_set=[(train_X.copy(), train_y.copy()),(valid_X.copy(), valid_y.copy())],\n",
    "        callbacks=[xgboost.callback.EarlyStopping(rounds=200)],\n",
    "        verbose=False)\n",
    "\n",
    "pred_XGB = model.predict(test_X.copy())\n",
    "accuracy = accuracy_score(test_y.copy(), pred_XGB.copy())\n",
    "print(lr, md, ne, ss, mc, g, pt, b, tm, em, o, l, a, cb, '\\naccuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_XGB = pd.DataFrame(pred_XGB)\n",
    "pred_XGB.columns  = ['XGB']\n",
    "pred_XGB.to_csv('XGB.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
