{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab2ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from  datetime import datetime as dt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9d9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/rian/Documents/2023/02.nonmun/01.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7305bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels 데이터 병합\n",
    "for p in tqdm([file_path + '/' + f + '/' for f in os.listdir(file_path) if f.split('.')[-1] != 'csv']):\n",
    "    under1 = [p + l for l in os.listdir(p)]\n",
    "    temp3_list = []\n",
    "    temp1 = pd.DataFrame()\n",
    "    # 연도별 유저 리스트\n",
    "    for u1 in under1:\n",
    "        under2 = [u1 + '/' + u for u in os.listdir(u1)]\n",
    "        temp2 = pd.DataFrame()\n",
    "        # 유저별 일자 리스트\n",
    "        for u2 in under2:\n",
    "            temp5 = pd.read_csv(glob.glob(u2 + '/*.csv')[0])\n",
    "            temp5.rename(columns={'ts':'timestamp'}, inplace=True)\n",
    "            temp5.set_index('timestamp', inplace=True)\n",
    "            temp2 = pd.concat([temp2, temp5], axis=0)\n",
    "\n",
    "        userId = pd.DataFrame([''.join([i for i in u1.split('/')[-1] if i.isdigit()])] * temp2.shape[0], index=temp2.index, columns=['userId'])\n",
    "        temp2 = pd.concat((temp2, userId), axis=1)\n",
    "        temp2.reset_index(drop=False, inplace=True)\n",
    "\n",
    "        temp1 = pd.concat([temp1, temp2], axis=0, ignore_index=True)\n",
    "    temp1 = temp1[['timestamp', 'userId'] + [c for c in temp1.columns if c not in ['timestamp', 'userId']]]\n",
    "    temp1.to_csv(f'C:/Users/rian/Documents/2023/02.nonmun/02.result/{p.split(\"/\")[-2]}_labels.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b398f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey, info 병합\n",
    "def merge_df(survey_df, info_df):\n",
    "    try:\n",
    "        survey_df['inputDt'] = pd.to_datetime(survey_df['inputDt'])\n",
    "        survey_df['date'] = survey_df['inputDt'].apply(lambda x:x - datetime.timedelta(days=1) if x.hour < 5 else x)\n",
    "        survey_df['date'] = pd.to_datetime(survey_df['date']).dt.date\n",
    "    except:\n",
    "        survey_df['startInput'] = pd.to_datetime(survey_df['startInput'])\n",
    "        survey_df['endInput'] = pd.to_datetime(survey_df['endInput']) \n",
    "        \n",
    "    survey_df.sort_values(by=['userId', 'date', 'amPm'], ignore_index=True, inplace=True)    \n",
    "    survey_df['userId'] = survey_df['userId'].astype('str')\n",
    "    survey_df['userId'] = survey_df['userId'].str.extract(r'(\\d+)').astype('int')\n",
    "    \n",
    "    info_df['userId'] = info_df['userId'].astype('str')\n",
    "    info_df['userId'] = info_df['userId'].str.extract(r'(\\d+)').astype('int')\n",
    "    info_df['startDt'] = pd.to_datetime(info_df['startDt'])\n",
    "    info_df['endDt'] = pd.to_datetime(info_df['endDt'])\n",
    "    \n",
    "    result_df = info_df.merge(right=survey_df, on=['userId'], how='right')\n",
    "    result_df.dropna(subset=['gender', 'age'], how='all', axis=0, inplace=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a89f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저 데이터 read\n",
    "# servey\n",
    "user_survey_20189 = pd.read_csv('C:/Users/rian/Documents/2023/02.nonmun/01.data\\\\user_survey_2019_2018.csv')\n",
    "# 2018, 2019 분리\n",
    "user_survey_2018 = user_survey_20189[user_survey_20189['userId'] < 100].reset_index(drop=True)\n",
    "user_survey_2019 = user_survey_20189[user_survey_20189['userId'] >= 100].reset_index(drop=True)\n",
    "del user_survey_20189\n",
    "user_survey_2020 = pd.read_csv('C:/Users/rian/Documents/2023/02.nonmun/01.data\\\\user_survey_2020.csv')\n",
    "\n",
    "# info\n",
    "user_info_20189 = pd.read_csv('C:/Users/rian/Documents/2023/02.nonmun/01.data\\\\user_info_2019_2018_updated.csv')\n",
    "user_info_20189['userId'] = user_info_20189['userId'].str.extract(r'(\\d+)').astype('int')\n",
    "# 2018, 2019 분리\n",
    "user_info_2018 = user_info_20189[(user_info_20189['userId'] < 100) & (user_info_20189['age'] < 40)].reset_index(drop=True)\n",
    "user_info_2019 = user_info_20189[(user_info_20189['userId'] >= 100) & (user_info_20189['age'] < 40)].reset_index(drop=True)\n",
    "del user_info_20189\n",
    "user_info_2020 = pd.read_csv('C:/Users/rian/Documents/2023/02.nonmun/01.data\\\\user_info_2020.csv')\n",
    "user_info_2020['userId'] = user_info_2020['userId'].str.extract(r'(\\d+)').astype('int')\n",
    "\n",
    "# id, 날짜에 맞추어 데이터 병합\n",
    "lifelog_2018 = merge_df(user_survey_2018.copy(), user_info_2018.copy())\n",
    "lifelog_2019 = merge_df(user_survey_2019.copy(), user_info_2019.copy())\n",
    "lifelog_2020 = merge_df(user_survey_2020.copy(), user_info_2020.copy())\n",
    "\n",
    "del user_survey_2018\n",
    "del user_info_2018\n",
    "del user_survey_2019\n",
    "del user_info_2019\n",
    "del user_survey_2020\n",
    "del user_info_2020\n",
    "\n",
    "# lifelog_2018.to_csv('C:/Users/rian/Documents/2023/02.nonmun/02.result/2018_tmp2.csv', header=True, index=False)\n",
    "# lifelog_2019.to_csv('C:/Users/rian/Documents/2023/02.nonmun/02.result/2019_tmp2.csv', header=True, index=False)\n",
    "# lifelog_2020.to_csv('C:/Users/rian/Documents/2023/02.nonmun/02.result/2020_tmp2.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d76d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = 'C:/Users/rian/Documents/2023/02.nonmun/02.result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16624d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 데이터 read\n",
    "label_2018 = pd.read_csv(labels_path + '/' + 'dataset_2018_labels.csv')\n",
    "label_2019 = pd.read_csv(labels_path + '/' + 'dataset_2019_labels.csv')\n",
    "label_2020 = pd.concat([pd.read_csv(labels_path + '/' + 'user01-06_labels.csv'),\n",
    "                        pd.read_csv(labels_path + '/' + 'user07-10_labels.csv'),\n",
    "                        pd.read_csv(labels_path + '/' + 'user11-12_labels.csv'),\n",
    "                        pd.read_csv(labels_path + '/' + 'user21-25_labels.csv'),\n",
    "                        pd.read_csv(labels_path + '/' + 'user26-30_labels.csv')], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c51b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_2018['timestamp'] = pd.to_datetime(label_2018['timestamp'], unit='s')\n",
    "label_2019['timestamp'] = pd.to_datetime(label_2019['timestamp'], unit='s')\n",
    "label_2020['timestamp'] = pd.to_datetime(label_2020['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd08b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 데이터 집계\n",
    "def count_df(df):\n",
    "    dict_temp = {}\n",
    "    i = 0\n",
    "    \n",
    "    for Id, content in df.groupby('userId'):\n",
    "        content.set_index('timestamp', inplace=True)\n",
    "        \n",
    "        for d, content2 in content.groupby(by=content.index.date):\n",
    "            dict_temp[i] = [d, Id]\n",
    "            \n",
    "            for c in ['sleep', 'personal_care', 'work', 'study', 'household', 'care_housemem', 'recreation_media', 'entertainment',\n",
    "                      'outdoor_act', 'hobby', 'recreation_etc', 'shop', 'communitiy_interaction', 'travel', 'meal', 'socialising']:\n",
    "                dict_temp[i] += [content2[content2['action'] == c].shape[0]]\n",
    "                \n",
    "            try:\n",
    "                # ALONE\n",
    "                dict_temp[i] += [content2[content2['condition'] <= 0].shape[0]]\n",
    "                # with\n",
    "                dict_temp[i] += [content2[content2['condition'] > 0].shape[0]]\n",
    "            except:\n",
    "                # ALONE\n",
    "                dict_temp[i] += [content2[content2['condition'] == 'ALONE'].shape[0]]\n",
    "                # with\n",
    "                dict_temp[i] += [content2[content2['condition'] != 'ALONE'].shape[0]]\n",
    "                \n",
    "            # with_families\n",
    "            dict_temp[i] += [content2[content2['conditionSub1Option'] == 1.0].shape[0]]\n",
    "            # with_friends\n",
    "            dict_temp[i] += [content2[content2['conditionSub1Option'] == 2.0].shape[0]]\n",
    "            # with_colleagues\n",
    "            dict_temp[i] += [content2[content2['conditionSub1Option'] == 3.0].shape[0]]\n",
    "            # acquaintances\n",
    "            dict_temp[i] += [content2[content2['conditionSub1Option'] == 4.0].shape[0]]\n",
    "            # with_unknown\n",
    "            dict_temp[i] += [content2[content2['conditionSub1Option'].isnull()].shape[0]]\n",
    "            \n",
    "            # place\n",
    "            for p in ['home', 'workplace', 'restaurant', 'outdoor', 'other_indoor']:\n",
    "                dict_temp[i] += [content2[content2['place'] == p].shape[0]]\n",
    "            for eP in range(1, 8):\n",
    "                dict_temp[i] += [content2[content2['emotionPositive'] == float(eP)].shape[0]]\n",
    "            for eT in range(1, 8):\n",
    "                dict_temp[i] += [content2[content2['emotionTension'] == float(eT)].shape[0]]\n",
    "                \n",
    "            # in_vehicle\n",
    "            dict_temp[i] += [content2[content2['activity'] == 0].shape[0]]\n",
    "            # on_bicycle\n",
    "            dict_temp[i] += [content2[content2['activity'] == 1].shape[0]]\n",
    "            # on_foot\n",
    "            dict_temp[i] += [content2[content2['activity'] == 2].shape[0]]\n",
    "            # still\n",
    "            dict_temp[i] += [content2[content2['activity'] == 3].shape[0]]\n",
    "#             # unknown\n",
    "#             dict_temp[i] += [content2[content2['activity'] == 4].shape[0]]\n",
    "#             # tilting\n",
    "#             dict_temp[i] += [content2[content2['activity'] == 5].shape[0]]\n",
    "#             # walking\n",
    "#             dict_temp[i] += [content2[content2['activity'] == 7].shape[0]]\n",
    "#             # running\n",
    "#             dict_temp[i] += [content2[content2['activity'] == 8].shape[0]]\n",
    "            i += 1\n",
    "\n",
    "    count_labels = pd.DataFrame(dict_temp).T\n",
    "    count_labels.columns = ['date', 'userId', 'sleep', 'personal_care', 'work', 'study', 'household',\n",
    "                            'care_housemem', 'recreation_media', 'entertainment', 'outdoor_act',\n",
    "                            'hobby', 'recreation_etc', 'shop', 'communitiy_interaction', 'travel',\n",
    "                            'meal', 'socialising', 'ALONE', 'WITH', 'with_families', 'with_friends',\n",
    "                            'with_colleagues', 'acquaintances', 'with_unknown', 'home', 'workplace',\n",
    "                            'restaurant', 'outdoor', 'other_indoor',\n",
    "                            'emotionPositive1', 'emotionPositive2', 'emotionPositive3', 'emotionPositive4',\n",
    "                            'emotionPositive5', 'emotionPositive6', 'emotionPositive7',\n",
    "                            'emotionTension1', 'emotionTension2', 'emotionTension3', 'emotionTension4',\n",
    "                            'emotionTension5', 'emotionTension6', 'emotionTension7',\n",
    "                            'in_vehicle', 'on_bicycle', 'on_foot', 'still'] # , 'unknown', 'tilting', 'walking', 'running']\n",
    "    \n",
    "    count_labels['household'] = count_labels['household'] + count_labels['care_housemem']\n",
    "    count_labels.drop(columns=['care_housemem'], inplace=True)\n",
    "    count_labels['userId'] = count_labels['userId'].astype('str')\n",
    "    count_labels['date'] = pd.to_datetime(count_labels['date'])\n",
    "    \n",
    "    return count_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7590e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연도별, 유저별 label 집계\n",
    "count_2018 = count_df(label_2018.copy())\n",
    "count_2019 = count_df(label_2019.copy())\n",
    "count_2020 = count_df(label_2020.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cde8708",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ = ['userId', 'gender', 'age', 'date']\n",
    "amCol = ['sleep_quality', 'sleepProblem', 'dream', 'amCondition', 'amEmotion']\n",
    "pmCol = ['pmEmotion', 'pmStress']\n",
    "comCol = ['caffeine', 'alcohol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d95318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey 집계\n",
    "def survey_count(df):\n",
    "    try:\n",
    "        df['amCaffeine'].fillna(df['pmCaffeine'], inplace=True)\n",
    "        df.rename(columns={'amCaffeine':'caffeine'}, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df.rename(columns={'sleep':'sleep_quality'}, inplace=True)\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])    \n",
    "    df['userId'] = df['userId'].astype('str')\n",
    "    \n",
    "    for c in comCol:\n",
    "        df.loc[df[df[c].isnull() == False].index, [c]] = 1\n",
    "        df[c].fillna(0, inplace=True)\n",
    "\n",
    "    result = pd.DataFrame(columns=['date', 'userId', 'gender', 'age',\n",
    "                                   'sleep_quality', 'sleepProblem', 'dream',\n",
    "                                   'amCondition', 'amEmotion', 'pmEmotion', 'caffeine', 'alcohol',\n",
    "                                   'pmStress'])\n",
    "\n",
    "    for g, content in df.groupby(by=index_):\n",
    "        temp = {}\n",
    "        for i in index_:\n",
    "            temp[i] = content.iloc[0][i]\n",
    "\n",
    "        amContent = content[content['amPm'] == 'am']\n",
    "        for a in amCol:\n",
    "            try:\n",
    "                temp[a] = amContent.iloc[0][a]\n",
    "            except:\n",
    "                temp[a] = np.nan\n",
    "                \n",
    "        pmContent = content[content['amPm'] == 'pm']\n",
    "        for p in pmCol:\n",
    "            try:\n",
    "                temp[p] = pmContent.iloc[0][p]\n",
    "            except:\n",
    "                temp[p] = np.nan\n",
    "                \n",
    "        del amContent\n",
    "        del pmContent\n",
    "        \n",
    "        for c in comCol:\n",
    "            temp[c] = 0 if content[c].sum() <= 0 else 1\n",
    "\n",
    "        result = result.append(temp, ignore_index=True)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82f33e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# survey 집계\n",
    "lifelog_data_2018 = survey_count(lifelog_2018.copy()).merge(count_2018.copy(), on=['date', 'userId'], how='inner').dropna()\n",
    "lifelog_data_2019 = survey_count(lifelog_2019.copy()).merge(count_2019.copy(), on=['date', 'userId'], how='inner').dropna()\n",
    "lifelog_data_2020 = survey_count(lifelog_2020.copy()).merge(count_2020.copy(), on=['date', 'userId'], how='inner').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd49b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifelog_data_2018.to_csv(r'C:\\Users\\rian\\Documents\\2023\\02.nonmun\\02.result\\lifelog_data_2018.csv', index=False)\n",
    "lifelog_data_2019.to_csv(r'C:\\Users\\rian\\Documents\\2023\\02.nonmun\\02.result\\lifelog_data_2019.csv', index=False)\n",
    "lifelog_data_2020.to_csv(r'C:\\Users\\rian\\Documents\\2023\\02.nonmun\\02.result\\lifelog_data_2020.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
