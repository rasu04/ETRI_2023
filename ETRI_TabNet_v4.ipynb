{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gRTQWoCOlkD0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rian\\miniconda3\\envs\\nonmun\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pytorch_tabnet.multitask import TabNetMultiTaskClassifier\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineering(n, d):\n",
    "    # 성별 인코딩\n",
    "    d['gender'] = d['gender'].apply(lambda x:0 if x == 'M' else 1)\n",
    "    # 날짜 변환\n",
    "    d['date'] = pd.to_datetime(d['date'])\n",
    "    # 스트레스(target)\n",
    "#     d['pmStress'] = d['pmStress'] - 1\n",
    "    \n",
    "    \n",
    "    # 이 아래부터는 다 쓸 필요는 없고, 결과나 편의에 따라서 사용하시면 됩니다!\n",
    "    \n",
    "    # 감정변화비율 = 오후감정/오전감정\n",
    "    d['emotionChangeRate'] = d['pmEmotion'] / d['amEmotion']\n",
    "    # 긍정변화평균 = emotion1~7의 평균\n",
    "    d['positiveMean'] = d.filter(regex='Positive').mean(axis=1)\n",
    "    # 긴장변화평균 = emotion1~7의 평균\n",
    "    d['tensionnMean'] = d.filter(regex='Tension').mean(axis=1)\n",
    "    \n",
    "    # 긍정비율 = Positive5~7 / 1~3\n",
    "    d['positiveRate'] = d[['emotionPositive5', 'emotionPositive6', 'emotionPositive7']].sum(axis=1) / d[['emotionPositive1', 'emotionPositive2', 'emotionPositive3']].sum(axis=1)\n",
    "    # 긴장비율 = Tension5~7 / 1~3\n",
    "    d['tensionRate'] = d[['emotionTension5', 'emotionTension6', 'emotionTension7']].sum(axis=1) / d[['emotionTension1', 'emotionTension2', 'emotionTension3']].sum(axis=1)\n",
    "    \n",
    "    # 긍정감정의 임시 테이블\n",
    "    pos_temp = d.filter(regex='Positive')\n",
    "    # 가장 높은 긍정감정의 숫자(1~7)\n",
    "    d['topPositive'] = pos_temp.idxmax(axis=1).apply(lambda x:int(x[-1]))\n",
    "    # 가장 낮은 긍정감정의 숫자(1~7)\n",
    "    d['botPositive'] = pos_temp.idxmin(axis=1).apply(lambda x:int(x[-1]))\n",
    "    \n",
    "    # 긍정 수치 1~7 * count 수\n",
    "    for p, c in enumerate(pos_temp.columns):\n",
    "        d.loc[:, [c]] = d.loc[:, [c]] * (p+1)\n",
    "        \n",
    "    del pos_temp\n",
    "    \n",
    "    # 긴장감정의 임시 테이블\n",
    "    ten_temp = d.filter(regex='Tension')\n",
    "    # 가장 높은 긴장감정의 숫자(1~7)\n",
    "    d['topTension'] = ten_temp.idxmax(axis=1).apply(lambda x:int(x[-1]))\n",
    "    # 가장 낮은 긴장감정의 숫자(1~7)\n",
    "    d['botTension'] = ten_temp.idxmin(axis=1).apply(lambda x:int(x[-1]))\n",
    "    \n",
    "    # 긴장 수치 1~7 * count 수\n",
    "    for t, c in enumerate(ten_temp.columns):\n",
    "        d.loc[:, [c]] = d.loc[:, [c]] * (t+1)\n",
    "    \n",
    "    del ten_temp\n",
    "    \n",
    "    # 수치 반영 긍정 평균\n",
    "    d['positiveWMean'] = d.filter(regex='Positive').mean(axis=1)\n",
    "    # 수치 반영 긴장 평균\n",
    "    d['tensionWMean'] = d.filter(regex='Tension').mean(axis=1)\n",
    "    \n",
    "    # 수치 반영 긍정 비율\n",
    "    d['positiveWRate'] = d[['emotionPositive5', 'emotionPositive6', 'emotionPositive7']].sum(axis=1) / d[['emotionPositive1', 'emotionPositive2', 'emotionPositive3']].sum(axis=1)\n",
    "    # 수치 반영 긴장 비율\n",
    "    d['tensionWRate'] = d[['emotionTension5', 'emotionTension6', 'emotionTension7']].sum(axis=1) / d[['emotionTension1', 'emotionTension2', 'emotionTension3']].sum(axis=1)\n",
    "    \n",
    "    # 여기서부터는 그냥 막 만들어 본 피쳐들입니다...\n",
    "    \n",
    "    # 오전 컨디션에 긍정/긴장 반영 = 오전 컨디션 * (수치 반영 긍정 평균 + 수치 반영 긴장 평균) / 7 -> 수치가 1~7이니까 그냥 7로 나누어 봄ㅎㅎ..\n",
    "    d['aCmET'] = round(d['amCondition'] * (d['positiveWMean'] + d['tensionWMean']) / 7)\n",
    "    # 오전 감정에 긍정/긴장 반영 = 오전 감정 * (수치 반영 긍정 평균 + 수치 반영 긴장 평균) / 7 -> 이것도\n",
    "    d['aEmET'] = round(d['amEmotion'] * (d['positiveWMean'] + d['tensionWMean']) / 7)\n",
    "    # 오전 컨디션/감정에 긍정 긴장 반영한 것의 평균을 냄\n",
    "    d['aCEmET'] = round((d['aCmET'] + d['aEmET']) / 2)\n",
    "    \n",
    "    # 오전 컨디션 긍정/긴장 반영에 오후 감정을 더한 뒤 평균을 냄\n",
    "    d['aCmETpE'] = round((d['aCmET'] + d['pmEmotion']) / 2)\n",
    "    # 오전 감정 긍정/긴장 반영에 오후 감정을 더한 뒤 평균을 냄\n",
    "    d['aEmETpE'] = round((d['aEmET'] + d['pmEmotion']) / 2)\n",
    "    # 오전 컨디션/감정 긍정/긴장 반영에 오후 감정을 더한 뒤 평균을 냄\n",
    "    d['aCEmETpE'] = round((d['aCEmET'] + d['pmEmotion']) / 2)\n",
    "    \n",
    "    # 최고 수치를 반영한 오전 감정 = (오전 감정 * (최고 감정 + 최고 긴장)) / 14\n",
    "    d['aCtPT'] = round(d['amEmotion'] * (d['topPositive'] + d['topTension']) / 14)\n",
    "    # 최고 수치를 반영한 오전 컨디션 = (오전 감정 * (최고 감정 + 최고 긴장)) / 14\n",
    "    d['aEtPT'] = round(d['amCondition'] * (d['topPositive'] + d['topTension']) / 14)\n",
    "    # 최고 수치를 반영한 오후 감정 = (오전 감정 * (최고 감정 + 최고 긴장)) / 14\n",
    "    d['pEtPT'] = round(d['pmEmotion'] * (d['topPositive'] + d['topTension']) / 14)\n",
    "    \n",
    "    # 둘 중에 하나로 쓰거나 컬럼명 변경해서 모두 써도 됩니다.\n",
    "    # (최고 수치를 반영한 오전 컨디션 + 최고 수치를 반영한 오전 감정 + 최고 수치를 반영한 오후 감정) / 3\n",
    "    # (최고 수치를 반영한 오전 컨디션 + 최고 수치를 반영한 오전 감정 + 최고 수치를 반영한 오후 감정)\n",
    "#     d['aCEpEtPTm'] = round((d['aCtPT'] + d['aEtPT'] + d['pEtPT']) / 3)\n",
    "    d['aCEpEtPTm'] = (d['aCtPT'] + d['aEtPT'] + d['pEtPT'])\n",
    "    \n",
    "    # 긍정적인지 = 수치 반영 긍정 평균이 중앙값보다 크면 1 아니면 0\n",
    "    d['positive'] = d['positiveWRate'].apply(lambda x:1 if x > d['positiveWRate'].median() else 0)\n",
    "    # 부정적인지 = 수치 반영 긍정 평균이 중앙값보다 작으면 1 아니면 0\n",
    "    d['negative'] = d['positiveWRate'].apply(lambda x:1 if x < d['positiveWRate'].median() else 0)\n",
    "    \n",
    "    # 긴장 상태인지 = 수치 반영 긴장 평균이 중앙값보다 크면 1 아니면 0\n",
    "    d['aroused'] = d['tensionWRate'].apply(lambda x:1 if x > d['tensionWRate'].median() else 0)\n",
    "    # 편안한 상태인지 = 수치 반영 긴장 평균이 중앙값보다 작으면 1 아니면 0\n",
    "    d['relaxed'] = d['tensionWRate'].apply(lambda x:1 if x < d['tensionWRate'].median() else 0)\n",
    "    \n",
    "    # 활동 비율 = 자전거, 도보의 합 / 운송수단, 가만히 있기의 합\n",
    "    d['activityRate'] = d[['on_bicycle', 'on_foot']].sum(axis=1) / d[['in_vehicle', 'still']].sum(axis=1)\n",
    "    # 0으로 나누기된 것을 0으로 치환\n",
    "    d.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    d.dropna(inplace=True)\n",
    "    # random_state는 잘 나오는 것으로 바꿔보세요! 제가 해본 것 : 1111, 2222, 3333, 4444, 5555, 6666, 7777, 8888, 9999, 1234\n",
    "    d.sample(n=d.shape[0], random_state=5555)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mti7tu3Flbuq"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'C:\\lifelog_data_2018.csv')\n",
    "df2 = pd.read_csv(r'C:\\lifelog_data_2019.csv')\n",
    "df3 = pd.read_csv(r'C:\\lifelog_data_2020.csv')\n",
    "for n, d in enumerate([df1, df2, df3]):\n",
    "    globals() [f'df{n+1}'] = engineering(n, d.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cYDS9hVkQWkk"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRU5cQuRSHRo",
    "outputId": "a9d0f32d-2648-425b-b4bd-7ac0b50484bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(667, 86) (299, 86) (105, 86)\n"
     ]
    }
   ],
   "source": [
    "# way 1\n",
    "train = pd.DataFrame()\n",
    "valid = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "# 스트레스 5종을 골고루 나누기 위함\n",
    "for i in range(5):\n",
    "    train = pd.concat([train, df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][:round(len(df) / 5 * 0.7)]], axis=0)\n",
    "    valid = pd.concat([valid, df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][round(len(df) / 5 * 0.7):-round(len(df) / 5 * 0.1)]], axis=0)\n",
    "    test = pd.concat([test, df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][-round(len(df) / 5 * 0.1):]], axis=0)\n",
    "\n",
    "    # 동 수로 뽑을 때\n",
    "#     temp = df.loc[df['pmStress'] == np.unique(df['pmStress'])[i]][:112]\n",
    "#     train = pd.concat([train, temp[:round(112 * 0.7)]], axis=0)\n",
    "#     valid = pd.concat([valid, temp[round(112 * 0.7):-round(112 * 0.1)]], axis=0)\n",
    "#     test = pd.concat([test, temp[-round(112 * 0.1):]], axis=0)\n",
    "\n",
    "train = train.sample(n=train.shape[0]) # , random_state=1234)\n",
    "valid = valid.sample(n=valid.shape[0]) # , random_state=1234)\n",
    "test = test.sample(n=test.shape[0]) # , random_state=1234)\n",
    "print(train.shape, valid.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "d36q4TSPd5Pn"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train, test, valid], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "N1ZudUHuipyQ"
   },
   "outputs": [],
   "source": [
    "df = df[[c for c in df.columns if c not in ['userId', 'date']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "X_Z3CnSeeeg1"
   },
   "outputs": [],
   "source": [
    "# tabnet에서 사용되는 기법으로, index를 저장해두고 나중에 데이터셋을 나눔\n",
    "train_indices = train.index\n",
    "valid_indices = valid.index\n",
    "test_indices = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "z5HSz9s5epSi"
   },
   "outputs": [],
   "source": [
    "nunique = df.nunique()\n",
    "types = df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NC3Ph8qbeslm"
   },
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in df.columns:\n",
    "    if types[col] == 'object' or nunique[col] <= 7:\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(np.unique(df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HQoq6EDVfsDx"
   },
   "outputs": [],
   "source": [
    "# target 제외한 피처 추가\n",
    "features = [col for col in df.columns if col not in ['pmStress']] \n",
    "# 카테고리 피처 정보\n",
    "cat_idxs = [i for i, f in enumerate(features) if f in categorical_columns]\n",
    "cat_dims = [categorical_dims[f] for f in features if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gWZzHySyhaV8"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 분할\n",
    "X_train = df[features].values[train_indices]\n",
    "y_train = df['pmStress'].values[train_indices].reshape(-1, 1)\n",
    "\n",
    "X_valid = df[features].values[valid_indices]\n",
    "y_valid = df['pmStress'].values[valid_indices].reshape(-1, 1)\n",
    "\n",
    "X_test = df[features].values[test_indices]\n",
    "y_test = df['pmStress'].values[test_indices].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'sleep_quality', 'dream', 'amCondition', 'amEmotion', 'pmEmotion', 'caffeine', 'alcohol', 'pmStress', 'topPositive', 'botPositive', 'topTension', 'botTension', 'aCtPT', 'aEtPT', 'pEtPT', 'positive', 'negative', 'aroused', 'relaxed'] [0, 2, 4, 5, 6, 7, 8, 9, 60, 61, 62, 63, 74, 75, 76, 78, 79, 80, 81] [2, 5, 4, 5, 5, 5, 2, 2, 7, 7, 7, 7, 6, 6, 6, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(categorical_columns, cat_idxs, cat_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSyLARswmgFX",
    "outputId": "a21d12da-5534-47dd-b7f2-3dfb79319943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(667, 83) (667, 1) (299, 83) (299, 1) (105, 83) (105, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,\n",
    "y_train.shape,\n",
    "X_valid.shape,\n",
    "y_valid.shape,\n",
    "X_test.shape,\n",
    "y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LvZv35zzOgJA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== \n",
      " <class 'torch.optim.adam.Adam'> {'lr': 0.01} 4 24 1.3 10 0.95 entmax 16 logloss True \n",
      " accuracy : 0.5428571428571428\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "of = optim.Adam\n",
    "# optimizer params\n",
    "op = dict(lr=0.01)\n",
    "# steps\n",
    "ns = 4\n",
    "# n_d, n_a\n",
    "nd = 24\n",
    "# model gamma\n",
    "g = 1.3\n",
    "# step_size\n",
    "ss = 10\n",
    "# scheduler gamma\n",
    "gm = 0.95\n",
    "# mask_type\n",
    "mt = 'entmax'\n",
    "# batch size\n",
    "bs = 16\n",
    "# eval_metric\n",
    "em = 'logloss'\n",
    "# warm_start\n",
    "ws = True\n",
    "\n",
    "clf = TabNetMultiTaskClassifier(optimizer_fn=of, optimizer_params=op, scheduler_fn=optim.lr_scheduler.StepLR,\n",
    "n_steps=ns, n_d=nd, n_a=nd, gamma=g,\n",
    "scheduler_params={\"step_size\":ss, \"gamma\":gm}, \n",
    "mask_type=mt, verbose=0)\n",
    "\n",
    "clf.fit(X_train.copy(), y_train.copy(),\n",
    "        eval_set=[(X_valid.copy(), y_valid.copy())],\n",
    "        loss_fn=[torch.nn.functional.cross_entropy]*5,\n",
    "        max_epochs=30, \n",
    "        patience=0,\n",
    "        batch_size=bs,\n",
    "        eval_metric=[em],\n",
    "        warm_start=ws)\n",
    "preds = clf.predict(X_test.copy())\n",
    "accuracy = accuracy_score(y_test.copy(), np.array(preds.copy()[0]).astype('float').reshape(-1, 1))\n",
    "print(\"=\"*10, '\\n', of, op, ns, nd, g, ss, gm, mt, bs, em, ws, '\\n', 'accuracy :', accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
