{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf2028e-a3d6-4ea3-aee4-a549baea2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b58590c4-b25d-466e-a132-94b4a427b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = pd.read_csv('{파일경로}/SVC.csv')\n",
    "TabNet = pd.read_csv('{파일경로}/TabNet.csv')\n",
    "XGB = pd.read_csv('{파일경로}/XGB.csv')\n",
    "RF = pd.read_csv('{파일경로}/RandomForest.csv')\n",
    "test = pd.read_csv('{파일경로}/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7111e712-4def-443f-898a-cba697887367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 2) (105, 2) (105, 2) (105, 2) (105, 2)\n"
     ]
    }
   ],
   "source": [
    "print(SVC.shape, TabNet.shape, XGB.shape, RF.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b911973f-1578-40bd-9dd4-70cf1df1325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 인덱스가 중복으로 들어가 'Unnamed: 0' 컬럼열 삭제\n",
    "def drop_columns(df):\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_list = [SVC, TabNet, XGB, RF, test] # 해당 데이터 리스트\n",
    "\n",
    "for df in df_list:\n",
    "    drop_columns(df)\n",
    "df = pd.concat([SVC, XGB, RF, TabNet, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38012216-c796-4af7-8ce2-1dfc9b9025f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5368421052631579\n",
      "Iteration: 1\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.8\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5789473684210525\n",
      "Iteration: 2\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.8\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.4947368421052631\n",
      "Iteration: 3\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.9\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5473684210526315\n",
      "Iteration: 4\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.8\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5368421052631579\n",
      "Iteration: 5\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.8\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5789473684210527\n",
      "Iteration: 6\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.7\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5263157894736842\n",
      "Iteration: 7\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.7\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5684210526315789\n",
      "Iteration: 8\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.8\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5789473684210525\n",
      "Iteration: 9\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.6\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5684210526315789\n",
      "Iteration: 10\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.8\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5157894736842106\n",
      "Iteration: 11\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.9\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.4526315789473684\n",
      "Iteration: 12\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.8\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.6105263157894737\n",
      "Iteration: 13\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.8\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.4631578947368421\n",
      "Iteration: 14\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.7\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5894736842105263\n",
      "Iteration: 15\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.6\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.4947368421052631\n",
      "Iteration: 16\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.6\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5263157894736843\n",
      "Iteration: 17\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.7\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5052631578947369\n",
      "Iteration: 18\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.7\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5052631578947369\n",
      "Iteration: 19\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.8\n",
      "========================================================================================================================================================================================================\n",
      "n_estimators: 50, max_depth: None, max_features: 4, min_samples_split: 2, min_samples_leaf: 2, criterion: gini  -> accuracy: 0.5578947368421052\n",
      "Iteration: 20\n",
      "Best params: {'n_estimators': 50, 'max_depth': None, 'max_features': 4, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini'}\n",
      "Accuracy on test set: 0.9\n",
      "========================================================================================================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Accuracy\n",
       "0             0.8\n",
       "1             0.8\n",
       "2             0.9\n",
       "3             0.8\n",
       "4             0.8\n",
       "5             0.7\n",
       "6             0.7\n",
       "7             0.8\n",
       "8             0.6\n",
       "9             0.8\n",
       "10            0.9\n",
       "11            0.8\n",
       "12            0.8\n",
       "13            0.7\n",
       "14            0.6\n",
       "15            0.6\n",
       "16            0.7\n",
       "17            0.7\n",
       "18            0.8\n",
       "19            0.9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "random_state = 8888 # 랜덤 시드 설정\n",
    "n_est = [50] # 결정 트리 개수 설정\n",
    "max_d = [None] # 결정 트리의 최대 깊이\n",
    "max_f = [4] # 최대 특성 개수\n",
    "min_s_s = [2] # 최소 분리 샘플 수 \n",
    "min_s_l = [2] # 최소 잎새 샘플 수\n",
    "c = ['gini'] # 결정 트리 분리 기준 \n",
    "test_accuracy_list = [] # 각 반복에서 테스트 셋의 정확도를 저장할 리스트\n",
    "results = [] # 모든 반복에서 테스트 셋 정화도를 저장할 리스트\n",
    "\n",
    "smote = SMOTE() # 오버 샘플링 기법 중 SMOTE 사용\n",
    "\n",
    "X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "# X : pmStress 컬럼을 제외한 데이터 \n",
    "# y : 'pmStress'\n",
    "\n",
    "for i in range(20):\n",
    "    train = pd.DataFrame() # train data를 저장할 리스트\n",
    "    valid = pd.DataFrame() # validation data를 저장할 리스트\n",
    "    test = pd.DataFrame() # test data를 저장할 리스트\n",
    "    for j in range(5):\n",
    "        train = pd.concat([train, df.loc[df['pmStress'] == np.unique(df['pmStress'])[j]][:round(len(df) / 5 * 0.9)]], axis=0) # 90% test data\n",
    "        test = pd.concat([test, df.loc[df['pmStress'] == np.unique(df['pmStress'])[j]][-round(len(df) / 5 * 0.1):]], axis=0) # 10% test data\n",
    "\n",
    "    train = train.sample(n=train.shape[0]) # , random_state=1234)\n",
    "    test = test.sample(n=test.shape[0]) # , random_state=1234)\n",
    "    \n",
    "    X_train, y_train = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "    X_test, y_test = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "    \n",
    "    # 교차 검증 정확도를 달성하는 하이퍼파라미터 조합 선택\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    for n_estimators in n_est:\n",
    "        for max_depth in max_d:\n",
    "            for max_features in max_f:\n",
    "                for min_samples_split in min_s_s:\n",
    "                    for min_samples_leaf in min_s_l:\n",
    "                        for criterion in c:\n",
    "                            score_sum = 0\n",
    "                            # 데이터를 5개의 fold로 나누고, Shuffle = True로 지정하여 데이터를 랜덤으로 섞음\n",
    "                            # k-fold 교차검증을 수행하기 위해 train set과 validation data로 분리\n",
    "                            for train_index, val_index in KFold(n_splits=5, shuffle=True, random_state=random_state).split(train):\n",
    "                                X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "                                y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "                                \n",
    "                                # 오버 샘플링 기법 중 SMOTE 사용\n",
    "                                smote = SMOTE()\n",
    "                                # validation data가 아닌, train data에만 smote 기법을 사용\n",
    "                                X_train_kf_resampled, y_train_kf_resampled = smote.fit_resample(X_train_kf, y_train_kf)\n",
    "                                \n",
    "                                clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, \n",
    "                                                             min_samples_split=min_samples_split, criterion=criterion, n_jobs=-1)\n",
    "                                clf.fit(X_train_kf_resampled, y_train_kf_resampled)\n",
    "                                score_sum += accuracy_score(y_val_kf, clf.predict(X_val_kf)) #5번 교차검증의 정확도의 합\n",
    "                            score_avg = score_sum / 5 # 5번 교차검증 정확도의 평균\n",
    "                            if score_avg > best_score: # best_score보다 score_sum이 클 경우 best_score를 score_avg로 업데이트하고 헤딩 파라미터 조합을 best_params에 저장\n",
    "                                best_score = score_avg # best_score와 score_avg 값이 동일할 경우, False\n",
    "                                # 각 하이퍼파라미터의 값을 출력\n",
    "                                best_params = {'n_estimators': n_estimators, 'max_depth': max_depth, 'max_features': max_features, \n",
    "                                               'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'criterion': criterion}\n",
    "                            # best_score 의 하이퍼파라미터 값 출력\n",
    "                            print(f\"n_estimators: {n_estimators}, max_depth: {max_depth}, max_features: {max_features}, \"\n",
    "                                  f\"min_samples_split: {min_samples_split}, min_samples_leaf: {min_samples_leaf}, criterion: {criterion}\",\n",
    "                                  f\" -> accuracy: {score_avg}\")\n",
    "    # 하이퍼 파라미터 값을 갖고 랜덤포레스트 모델 적합                        \n",
    "    clf = RandomForestClassifier(**best_params)\n",
    "    clf.fit(X_train_kf, y_train_kf)\n",
    "    # 하이퍼 파라미터 값을 갖고, test data로 예측한 y_pred 값\n",
    "    y_pred_rf = clf.predict(X_test)\n",
    "    # 실제 test값과 예측값 사이의 정확도\n",
    "    accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "    results.append(accuracy)\n",
    "\n",
    "    print(f\"Iteration: {i+1}\") # 반복 횟수\n",
    "    print(f\"Best params: {best_params}\") # 하이퍼파라미터 조합\n",
    "    print(f\"Accuracy on test set: {accuracy}\") # accuracy\n",
    "    print('=='*100)\n",
    "\n",
    "    test_accuracy_list.append(accuracy) # 반복횟수에 따른 정확도를 저장\n",
    "\n",
    "result_rf = pd.DataFrame({'Test Accuracy': test_accuracy_list}) # 데이터프레임 형식으로 test_accuracy_list 저장                           \n",
    "result_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e26a3c-0005-4280-b1a0-ff85999ca5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
